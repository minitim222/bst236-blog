<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>arXiv Feed · Tim's Coding Blog</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container header-content">
        <div class="brand">
          <span class="brand-mark">&lt;/&gt;</span>
          <span class="brand-text">Tim's Coding Blog</span>
        </div>
        <nav class="nav">
          <a href="index.html" class="nav-link">Home</a>
          <a href="pacman.html" class="nav-link">Pac-Man Game</a>
          <a href="arxiv.html" class="nav-link active">arXiv Feed</a>
        </nav>
      </div>
    </header>

    <main class="page-main">
      <section class="container page-header">
        <div
          style="
            display: flex;
            justify-content: space-between;
            gap: 1rem;
            align-items: flex-end;
          "
        >
          <div>
            <div class="pill">
              <span class="pill-dot"></span>
              <span>Auto-updating feed</span>
            </div>
            <h1>Latest arXiv Papers</h1>
            <p>
              A nightly-updated list of recent arXiv papers based on my chosen
              keywords.
            </p>
          </div>
          <div
            style="
              text-align: right;
              font-size: 0.78rem;
              color: #9ca3af;
              line-height: 1.5;
            "
          >
            <div>Last updated: <span id="last-updated">2026-02-22 02:08 UTC</span></div>
            <div>Query: <span>statistics, causal+inference, machine+learning</span></div>
          </div>
        </div>
      </section>

      <section class="container">
        <div
          style="
            border-radius: 18px;
            border: 1px solid rgba(148, 163, 184, 0.55);
            background: radial-gradient(circle at top, #020617, #020617);
            box-shadow: 0 18px 45px rgba(15, 23, 42, 1);
            padding: 1.1rem 1.2rem 1.4rem;
          "
        >
          <div
            style="
              display: flex;
              justify-content: space-between;
              align-items: center;
              margin-bottom: 0.7rem;
              gap: 0.8rem;
            "
          >
            <h2
              style="
                margin: 0;
                font-size: 1.1rem;
                display: flex;
                align-items: center;
                gap: 0.35rem;
              "
            >
              <span>Recent papers</span>
            </h2>
            <span
              style="
                font-size: 0.8rem;
                color: #9ca3af;
                border-radius: 999px;
                padding: 0.18rem 0.6rem;
                border: 1px solid rgba(148, 163, 184, 0.45);
              "
              >Generated automatically by GitHub Actions</span
            >
          </div>

          <div class="paper-list">
            <article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17657v1" target="_blank" rel="noopener noreferrer">
      Realization of fractional Fermi seas
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Yi Zeng, Alvise Bastianello, Sudipta Dhar, Zekui Wang, Xudong Yu, Milena Horvath, Grigori E. Astrakharchik, Yanliang Guo, Hanns-Christoph Nägerl, Manuele Landini</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">The Pauli exclusion principle is a cornerstone of quantum physics: it governs the structure of matter. Extensions of this principle, such as Haldane&#x27;s generalized exclusion statistics, predict the existence of exotic quantum states characterized by fractional Fermi seas (FFS), i.e. momentum distributions with uniform but fractional occupancies. Here, we report the experimental realization of fractional Fermi seas in an excited one-dimensional Bose gas prepared through ramping cycles in the interaction strength. The resulting excited yet stable Bose-gas states exhibit Friedel oscillations, smoking-gun signatures of the underlying FFS. The stabilization of these states offers an opportunity to deepen our understanding of quantum thermodynamics in the presence of exotic statistics and paves the way for applications in quantum information and sensing.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17657v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17654v1" target="_blank" rel="noopener noreferrer">
      Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Jiaqi Xi, Raghav Saboo, Luming Chen, Martin Wang, Sudeep Das</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">We propose a two-stage &quot;Mine and Refine&quot; contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17654v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17649v1" target="_blank" rel="noopener noreferrer">
      The Effectiveness of a Virtual Reality-Based Training Program for Improving Body Awareness in Children with Attention Deficit and Hyperactivity Disorder
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Aya Abdelnaem El-Basha, Ebtsam ELSayed Mahmoud ELSayes, Ahmad Al-Kabbany</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">This study investigates the effectiveness of a Virtual Reality (VR)-based training program in improving body awareness among children with Attention Deficit Hyperactivity Disorder (ADHD). Utilizing a quasi-experimental design, the research sample consisted of 10 children aged 4 to 7 years, with IQ scores ranging from 90 to 110. Participants were divided into an experimental group and a control group, with the experimental group receiving a structured VR intervention over three months, totaling 36 sessions. Assessment tools included the Stanford-Binet Intelligence Scale (5th Edition), the Conners Test for ADHD, and a researcher-prepared Body Awareness Scale. The results indicated statistically significant differences between pre-test and post-test scores for the experimental group, demonstrating the program&#x27;s efficacy in enhancing spatial awareness, body part identification, and motor expressions. Furthermore, follow-up assessments conducted one month after the intervention revealed no significant differences from the post-test results, confirming the sustainability and continuity of the program&#x27;s effects over time. The findings suggest that immersive VR environments provide a safe, engaging, and effective therapeutic medium for addressing psychomotor deficits in early childhood ADHD.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17649v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17641v1" target="_blank" rel="noopener noreferrer">
      FAMOSE: A ReAct Approach to Automated Feature Discovery
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Keith Burghardt, Jienan Liu, Sadman Sakib, Yuning Hao, Bo Li</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation tools within an agent architecture. To our knowledge, FAMOSE represents the first application of an agentic ReAct framework to automated feature engineering, especially for both regression and classification tasks. Extensive experiments demonstrate that FAMOSE is at or near the state-of-the-art on classification tasks (especially tasks with more than 10K instances, where ROC-AUC increases 0.23% on average), and achieves the state-of-the-art for regression tasks by reducing RMSE by 2.0% on average, while remaining more robust to errors than other algorithms. We hypothesize that FAMOSE&#x27;s strong performance is because ReAct allows the LLM context window to record (via iterative feature discovery and evaluation steps) what features did or did not work. This is similar to a few-shot prompt and guides the LLM to invent better, more innovative features. Our work offers evidence that AI agents are remarkably effective in solving problems that require highly inventive solutions, such as feature engineering.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17641v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17621v1" target="_blank" rel="noopener noreferrer">
      Method to Compute Pointing Displacement, Smear, and Jitter Covariances for Optical Payloads
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Peter Seiler, Mark E. Pittelkau, Felix Biertümpfel</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">This paper presents a method to assess the pointing and image motion performance of optical payloads in the presence of image displacement (shift), smear, and jitter. The method assumes the motion is a stationary random process over an image exposure interval. Displacement, smear, and jitter covariances are computed from the solution to a Lyapunov differential equation. These covariances parameterize statistical image motion modulation transfer functions (MTFs), and they can be used to verify pointing and image motion MTF requirements. The method in the present paper extends a previous method to include smear, as well as displacement, and hence jitter. The approach in the present paper also leads, as a special case, to a more efficient method to compute the displacement covariance than the previous method. Numerical examples illustrate the proposed method.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17621v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17619v1" target="_blank" rel="noopener noreferrer">
      EDRP: Enhanced Dynamic Relay Point Protocol for Data Dissemination in Multi-hop Wireless IoT Networks
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Jothi Prasanna Shanmuga Sundaram, Magzhan Gabidolla, Luis Fujarte, Shawn Duong, Jianlin Guo, Toshiaki Koike-Akino, Pu, Wang, Kieran Parsons, Philip V. Orlik, Takenori Sumi, Yukimasa Nagai, Miguel A. Carreira-Perpinan, Alberto E. Cerpa</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Emerging IoT applications are transitioning from battery-powered to grid-powered nodes. DRP, a contention-based data dissemination protocol, was developed for these applications. Traditional contention-based protocols resolve collisions through control packet exchanges, significantly reducing goodput. DRP mitigates this issue by employing a distributed delay timer mechanism that assigns transmission-start delays based on the average link quality between a sender and its children, prioritizing highly connected nodes for early transmission. However, our in-field experiments reveal that DRP is unable to accommodate real-world link quality fluctuations, leading to overlapping transmissions from multiple senders. This overlap triggers CSMA&#x27;s random back-off delays, ultimately degrading the goodput performance. To address these shortcomings, we first conduct a theoretical analysis that characterizes the design requirements induced by real-world link quality fluctuations and DRP&#x27;s passive acknowledgments. Guided by this analysis, we design EDRP, which integrates two novel components: (i) Link-Quality Aware CSMA (LQ-CSMA) and (ii) a Machine Learning-based Block Size Selection (ML-BSS) algorithm for rateless codes. LQ-CSMA dynamically restricts the back-off delay range based on real-time link quality estimates, ensuring that nodes with stronger connectivity experience shorter delays. ML-BSS algorithm predicts future link quality conditions and optimally adjusts the block size for rateless coding, reducing overhead and enhancing goodput. In-field evaluations of EDRP demonstrate an average goodput improvement of 39.43\% than the competing protocols.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17619v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17618v1" target="_blank" rel="noopener noreferrer">
      3D Gravity and Chaos in CFTs with Fermions
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Jan Boruch, Elisa Tabor, Gustavo J. Turiaci</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Pure 3d gravity in AdS is believed to admit a holographic description in terms of 2d CFT. We introduce a theory of fermionic 3d gravity where we sum over geometries equipped with spin structure, and propose it is holographically described by fermionic 2d CFT data. We evaluate the leading contributions to the gravity path integral with one and two torus boundaries, extracting both the spectrum and its spectral statistics from the torus wormhole. Strikingly, the theory has fermionic black hole microstates, even in the absence of bulk fermionic matter. We then incorporate subtle bulk topological field theories, classified by appropriate cobordism groups, and evaluate the one and two-boundary torus partition functions. The spectral statistics we derive from gravity are shown, in all cases, to be consistent with the pattern of anomalies expected from classifications of fermionic 2d CFT. We also define a version of RMT$_2$, a random-matrix framework compatible with the symmetries of 2d CFTs, which naturally accommodates fermionic spectra and reproduces our gravitational results across all cases we analyze.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17618v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17614v1" target="_blank" rel="noopener noreferrer">
      Guarding the Middle: Protecting Intermediate Representations in Federated Split Learning
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Obaidullah Zaland, Sajib Mistry, Monowar Bhuyan</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Big data scenarios, where massive, heterogeneous datasets are distributed across clients, demand scalable, privacy-preserving learning methods. Federated learning (FL) enables decentralized training of machine learning (ML) models across clients without data centralization. Decentralized training, however, introduces a computational burden on client devices. U-shaped federated split learning (UFSL) offloads a fraction of the client computation to the server while keeping both data and labels on the clients&#x27; side. However, the intermediate representations (i.e., smashed data) shared by clients with the server are prone to exposing clients&#x27; private data. To reduce exposure of client data through intermediate data representations, this work proposes k-anonymous differentially private UFSL (KD-UFSL), which leverages privacy-enhancing techniques such as microaggregation and differential privacy to minimize data leakage from the smashed data transferred to the server. We first demonstrate that an adversary can access private client data from intermediate representations via a data-reconstruction attack, and then present a privacy-enhancing solution, KD-UFSL, to mitigate this risk. Our experiments indicate that, alongside increasing the mean squared error between the actual and reconstructed images by up to 50% in some cases, KD-UFSL also decreases the structural similarity between them by up to 40% on four benchmarking datasets. More importantly, KD-UFSL improves privacy while preserving the utility of the global model. This highlights its suitability for large-scale big data applications where privacy and utility must be balanced.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17614v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17608v1" target="_blank" rel="noopener noreferrer">
      Towards Anytime-Valid Statistical Watermarking
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Baihe Huang, Eric Xu, Kannan Ramchandran, Jiantao Jiao, Michael I. Jordan</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17608v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17606v1" target="_blank" rel="noopener noreferrer">
      Characterization of compressible fluctuations in solar wind streams dominated by balanced and imbalanced turbulence: Parker Solar Probe, Solar Orbiter and Wind observations
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">C. A. Gonzalez, C. Gonzalez, A. Tenerani</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Characterizing compressible fluctuations in the solar wind is essential for understanding their role in solar wind acceleration and heating, yet their origin and evolution across different turbulence regimes remain poorly understood. In this study, we carry out a statistical analysis of the properties of compressible fluctuations in solar wind dominated by balanced and imbalanced turbulence. Using in-situ measurements from Wind, Solar Orbiter, and Parker Solar Probe, we investigate the scale dependence of density and magnetic field fluctuations and their correlations with plasma beta and radial distance. Our results indicate that solar wind compressibility is likely affected by both expansion effects and compressible dynamics governed by local plasma conditions. The non-Alfvenic wind is dominated by anti-correlated fluctuations, whereas the Alfvenic wind contains a mixture of correlated and anti-correlated fluctuations, though the latter remain prevalent. While the anti-correlated component is consistent with MHD slow magnetosonic modes, the correlated (fast mode-like) component is not reproduced by predictions from either linear MHD theory or nonlinear models of forced compressible fluctuations. Nevertheless, the dominant slow mode component explains the observed dependence on beta and the enhanced density fluctuations measured by Parker Solar Probe. This further suggests that slow mode waves contribute significantly to the compressible energy budget near the Sun and may play an important role in solar wind heating and acceleration close to the Sun.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17606v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17598v1" target="_blank" rel="noopener noreferrer">
      The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\rightarrow$LLM Pipelines?
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Jayadev Billa</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Current speech LLMs largely perform implicit ASR: on tasks solvable from a transcript, they are behaviorally and mechanistically equivalent to simple Whisper$\to$LLM cascades. We show this through matched-backbone testing across four speech LLMs and six tasks, controlling for the LLM backbone for the first time. Ultravox is statistically indistinguishable from its matched cascade ($κ{=}0.93$); logit lens reveals literal text emerging in hidden states; LEACE concept erasure confirms text representations are causally necessary in both architectures tested, collapsing accuracy to near-zero. Qwen2-Audio genuinely diverges, revealing cascade equivalence is architecture-dependent, not universal. For most deployed use cases, current speech LLMs are expensive cascades, and under noise, they are worse ones, with clean-condition advantages reversing by up to 7.6% at 0 dB.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17598v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17594v1" target="_blank" rel="noopener noreferrer">
      AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Lance Ying, Ryan Truong, Prafull Sharma, Kaiya Ivy Zhao, Nathan Cloos, Kelsey R. Allen, Thomas L. Griffiths, Katherine M. Collins, José Hernández-Orallo, Phillip Isola, Samuel J. Gershman, Joshua B. Tenenbaum</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a &quot;human game&quot; to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the &quot;Multiverse of Human Games&quot;. Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17594v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17592v1" target="_blank" rel="noopener noreferrer">
      BMW: Bayesian Model-Assisted Adaptive Phase II Clinical Trial Design for Win Ratio Statistic
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Di Zhu, Yong Zang</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">The win ratio (WR) statistic is increasingly used to evaluate treatment effects based on prioritized composite endpoints, yet existing Bayesian adaptive designs are not directly applicable because the WR is a summary statistic derived from pairwise comparisons and does not correspond to a unique data-generating mechanism. We propose a Bayesian model-assisted adaptive design for randomized phase II clinical trials based on the WR statistic, referred to as the BMW design. The proposed design uses the joint asymptotic distribution of WR test statistics across interim and final analyses to compute posterior probabilities without specifying the underlying outcome distribution. The BMW design allows flexible interim monitoring with early stopping for futility or superiority and is extended to jointly evaluate efficacy and toxicity using a graphical testing procedure that controls the family-wise error rate (FWER). Simulation studies demonstrate that the BMW design maintains valid type I error and FWER control, achieves power comparable to conventional methods, and substantially reduces expected sample size. An R Shiny application is provided to facilitate practical implementation.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17592v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17586v1" target="_blank" rel="noopener noreferrer">
      Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Antonio Guillen-Perez</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17586v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17577v1" target="_blank" rel="noopener noreferrer">
      Simultaneous Blackwell Approachability and Applications to Multiclass Omniprediction
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Lunjia Hu, Kevin Tian, Chutong Yang</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Omniprediction is a learning problem that requires suboptimality bounds for each of a family of losses $\mathcal{L}$ against a family of comparator predictors $\mathcal{C}$. We initiate the study of omniprediction in a multiclass setting, where the comparator family $\mathcal{C}$ may be infinite. Our main result is an extension of the recent binary omniprediction algorithm of [OKK25] to the multiclass setting, with sample complexity (in statistical settings) or regret horizon (in online settings) $\approx \varepsilon^{-(k+1)}$, for $\varepsilon$-omniprediction in a $k$-class prediction problem. En route to proving this result, we design a framework of potential broader interest for solving Blackwell approachability problems where multiple sets must simultaneously be approached via coupled actions.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17577v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17563v1" target="_blank" rel="noopener noreferrer">
      Compact Representation of Particle-Collision Events for Physics-Informed Machine Learning
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Wasikul Islam, Sergei Chekanov</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">We introduce a compact, physics-driven event representation, RMM-C46, designed to compress the high-dimensional rapidity mass matrix (RMM) into a low-dimensional, interpretable feature set suitable for physics-informed machine learning (ML) and quantum computing applications. The full RMM encodes detailed pairwise correlations among jets, b-jets, leptons, photons, and missing transverse energy but contains more than a thousand values per event, making it computationally heavy for large-scale training and incompatible with current low-qubit quantum devices. The proposed RMM-C46 input space for ML preserves the physical block structure of the RMM through aggregated invariant mass, rapidity difference, and transverse energy components, reducing the size of the original RMM by over an order of magnitude while maintaining interpretability. Applied to simulated proton-proton collisions at centre-of-mass energy of 13.6 TeV, these representations match or exceed the discriminative performance of the full RMM in both supervised and unsupervised ML tasks. Their compactness, stability, and physics transparency also make them naturally compatible with near-term quantum machine learning architectures. RMM-C46 provides a scalable, efficient, and quantum-ready alternative to the full RMM for next-generation collider physics analyses.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17563v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17555v1" target="_blank" rel="noopener noreferrer">
      GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Zixu Cheng, Da Li, Jian Hu, Ziquan Liu, Wei Li, Shaogang Gong</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or video summaries for video reasoning, such modeling still lacks causal understanding. Without explicit causal structure modeling within and across video events, these models suffer from hallucinations during the video reasoning. In this work, we propose GraphThinker, a reinforcement finetuning-based method that constructs structural event-level scene graphs and enhances visual grounding to jointly reduce hallucinations in video reasoning. Specifically, we first employ an MLLM to construct an event-based video scene graph (EVSG) that explicitly models both intra- and inter-event relations, and incorporate these formed scene graphs into the MLLM as an intermediate thinking process. We also introduce a visual attention reward during reinforcement finetuning, which strengthens video grounding and further mitigates hallucinations. We evaluate GraphThinker on two datasets, RexTime and VidHalluc, where it shows superior ability to capture object and event relations with more precise event localization, reducing hallucinations in video reasoning compared to prior methods.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17555v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17543v1" target="_blank" rel="noopener noreferrer">
      genriesz: A Python Package for Automatic Debiased Machine Learning with Generalized Riesz Regression
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Masahiro Kato</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">Efficient estimation of causal and structural parameters can be automated using the Riesz representation theorem and debiased machine learning (DML). We present genriesz, an open-source Python package that implements automatic DML and generalized Riesz regression, a unified framework for estimating Riesz representers by minimizing empirical Bregman divergences. This framework includes covariate balancing, nearest-neighbor matching, calibrated estimation, and density ratio estimation as special cases. A key design principle of the package is automatic regressor balancing (ARB): given a Bregman generator $g$ and a representer model class, genriesz} automatically constructs a compatible link function so that the generalized Riesz regression estimator satisfies balancing (moment-matching) optimality conditions in a user-chosen basis. The package provides a modulr interface for specifying (i) the target linear functional via a black-box evaluation oracle, (ii) the representer model via basis functions (polynomial, RKHS approximations, random forest leaf encodings, neural embeddings, and a nearest-neighbor catchment basis), and (iii) the Bregman generator, with optional user-supplied derivatives. It returns regression adjustment (RA), Riesz weighting (RW), augmented Riesz weighting (ARW), and TMLE-style estimators with cross-fitting, confidence intervals, and $p$-values. We highlight representative workflows for estimation problems such as the average treatment effect (ATE), ATE on treated (ATT), and average marginal effect estimation. The Python package is available at https://github.com/MasaKat0/genriesz and on PyPI.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17543v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17532v1" target="_blank" rel="noopener noreferrer">
      Systematic Evaluation of Single-Cell Foundation Model Interpretability Reveals Attention Captures Co-Expression Rather Than Unique Regulatory Signal
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Ihor Kendiukhov</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">We present a systematic evaluation framework - thirty-seven analyses, 153 statistical tests, four cell types, two perturbation modalities - for assessing mechanistic interpretability in single-cell foundation models. Applying this framework to scGPT and Geneformer, we find that attention patterns encode structured biological information with layer-specific organisation - protein-protein interactions in early layers, transcriptional regulation in late layers - but this structure provides no incremental value for perturbation prediction: trivial gene-level baselines outperform both attention and correlation edges (AUROC 0.81-0.88 versus 0.70), pairwise edge scores add zero predictive contribution, and causal ablation of regulatory heads produces no degradation. These findings generalise from K562 to RPE1 cells; the attention-correlation relationship is context-dependent, but gene-level dominance is universal. Cell-State Stratified Interpretability (CSSI) addresses an attention-specific scaling failure, improving GRN recovery up to 1.85x. The framework establishes reusable quality-control standards for the field.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17532v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.17528v1" target="_blank" rel="noopener noreferrer">
      Interpretable Machine Learning of Nanoparticle Stability through Topological Layer Embeddings
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Felipe Hawthorne, Leandro Seixas, James M. Almeida, Cristiano F. Woellner, Raphael M. Tromer</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-19</span>
  </p>
  <p class="paper-abstract">The stability of chemically complex nanoparticles is governed by an immense configurational space arising from heterogeneous local atomic environments across surface and interior regions. Efficiently identifying low-energy configurations within this space remains a central challenge for first-principles-based materials discovery, particularly when the available reference data are limited. Here, we introduce a data-efficient and physically interpretable machine-learning framework based on a fragmented, layer-resolved descriptor that explicitly decomposes nanoparticles into surface, intermediate, and core environments using a topology-driven definition. This representation preserves a compact and fixed feature dimensionality while retaining spatial resolution, enabling controlled emphasis on different regions of the nanoparticle through physically motivated weighting schemes. Coupled with gradient-boosted decision tree models and a ranking-based learning strategy, the proposed framework enables accurate identification of the most stable nanoparticle configurations using only a few hundred density functional theory reference calculations. Ranking performance metrics demonstrate near-saturation of correlation, high top-k recall, and rapidly vanishing regret at moderate training-set sizes, highlighting the strong data efficiency of the approach. Beyond predictive performance, layer-weighting and SHAP-based interpretability analyses reveal how surface segregation, coordination topology, and local chemical disorder contribute differently to stability across spatial regions of the nanoparticle. These insights provide a transparent physical interpretation of the learned models and establish a natural pathway toward active learning-driven exploration of complex nanoparticle configurational spaces.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.17528v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>
          </div>
        </div>
      </section>
    </main>

    <footer class="site-footer">
      <div class="container footer-content">
        <p>© <span id="year"></span> Tim's Coding Blog · arXiv feed</p>
      </div>
    </footer>

    <script>
      document.getElementById("year").textContent =
        new Date().getFullYear().toString();
    </script>
  </body>
  </html>

