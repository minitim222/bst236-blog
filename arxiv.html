<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>arXiv Feed · Tim's Coding Blog</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container header-content">
        <div class="brand">
          <span class="brand-mark">&lt;/&gt;</span>
          <span class="brand-text">Tim's Coding Blog</span>
        </div>
        <nav class="nav">
          <a href="index.html" class="nav-link">Home</a>
          <a href="pacman.html" class="nav-link">Pac-Man Game</a>
          <a href="arxiv.html" class="nav-link active">arXiv Feed</a>
        </nav>
      </div>
    </header>

    <main class="page-main">
      <section class="container page-header">
        <div
          style="
            display: flex;
            justify-content: space-between;
            gap: 1rem;
            align-items: flex-end;
          "
        >
          <div>
            <div class="pill">
              <span class="pill-dot"></span>
              <span>Auto-updating feed</span>
            </div>
            <h1>Latest arXiv Papers</h1>
            <p>
              A nightly-updated list of recent arXiv papers based on my chosen
              keywords.
            </p>
          </div>
          <div
            style="
              text-align: right;
              font-size: 0.78rem;
              color: #9ca3af;
              line-height: 1.5;
            "
          >
            <div>Last updated: <span id="last-updated">2026-02-17 19:30 UTC</span></div>
            <div>Query: <span>statistics, causal+inference, machine+learning</span></div>
          </div>
        </div>
      </section>

      <section class="container">
        <div
          style="
            border-radius: 18px;
            border: 1px solid rgba(148, 163, 184, 0.55);
            background: radial-gradient(circle at top, #020617, #020617);
            box-shadow: 0 18px 45px rgba(15, 23, 42, 1);
            padding: 1.1rem 1.2rem 1.4rem;
          "
        >
          <div
            style="
              display: flex;
              justify-content: space-between;
              align-items: center;
              margin-bottom: 0.7rem;
              gap: 0.8rem;
            "
          >
            <h2
              style="
                margin: 0;
                font-size: 1.1rem;
                display: flex;
                align-items: center;
                gap: 0.35rem;
              "
            >
              <span>Recent papers</span>
            </h2>
            <span
              style="
                font-size: 0.8rem;
                color: #9ca3af;
                border-radius: 999px;
                padding: 0.18rem 0.6rem;
                border: 1px solid rgba(148, 163, 184, 0.45);
              "
              >Generated automatically by GitHub Actions</span
            >
          </div>

          <div class="paper-list">
            <article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.15029v1" target="_blank" rel="noopener noreferrer">
      Symmetry in language statistics shapes the geometry of model representations
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Dhruva Karkada, Daniel J. Korchinski, Andres Nava, Matthieu Wyart, Yasaman Bahri</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Although learned representations underlie neural networks&#x27; success, their fundamental properties remain poorly understood. A striking example is the emergence of simple geometric structures in LLM representations: for example, calendar months organize into a circle, years form a smooth one-dimensional manifold, and cities&#x27; latitudes and longitudes can be decoded by a linear probe. We show that the statistics of language exhibit a translation symmetry -- e.g., the co-occurrence probability of two months depends only on the time interval between them -- and we prove that the latter governs the aforementioned geometric structures in high-dimensional word embedding models. Moreover, we find that these structures persist even when the co-occurrence statistics are strongly perturbed (for example, by removing all sentences in which two months appear together) and at moderate embedding dimension. We show that this robustness naturally emerges if the co-occurrence statistics are collectively controlled by an underlying continuous latent variable. We empirically validate this theoretical framework in word embedding models, text embedding models, and large language models.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.15029v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.15018v1" target="_blank" rel="noopener noreferrer">
      Neurosim: A Fast Simulator for Neuromorphic Robot Perception
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Richeek Das, Pratik Chaudhari</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Neurosim is a fast, real-time, high-performance library for simulating sensors such as dynamic vision sensors, RGB cameras, depth sensors, and inertial sensors. It can also simulate agile dynamics of multi-rotor vehicles in complex and dynamic environments. Neurosim can achieve frame rates as high as ~2700 FPS on a desktop GPU. Neurosim integrates with a ZeroMQ-based communication library called Cortex to facilitate seamless integration with machine learning and robotics workflows. Cortex provides a high-throughput, low-latency message-passing system for Python and C++ applications, with native support for NumPy arrays and PyTorch tensors. This paper discusses the design philosophy behind Neurosim and Cortex. It demonstrates how they can be used to (i) train neuromorphic perception and control algorithms, e.g., using self-supervised learning on time-synchronized multi-modal data, and (ii) test real-time implementations of these algorithms in closed-loop. Neurosim and Cortex are available at https://github.com/grasp-lyrl/neurosim .</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.15018v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14997v1" target="_blank" rel="noopener noreferrer">
      Spectral Convolution on Orbifolds for Geometric Deep Learning
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Tim Mangliers, Bernhard Mössner, Benjamin Himpel</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Geometric deep learning (GDL) deals with supervised learning on data domains that go beyond Euclidean structure, such as data with graph or manifold structure. Due to the demand that arises from application-related data, there is a need to identify further topological and geometric structures with which these use cases can be made accessible to machine learning. There are various techniques, such as spectral convolution, that form the basic building blocks for some convolutional neural network-like architectures on non-Euclidean data. In this paper, the concept of spectral convolution on orbifolds is introduced. This provides a building block for making learning on orbifold structured data accessible using GDL. The theory discussed is illustrated using an example from music theory.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14997v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14991v1" target="_blank" rel="noopener noreferrer">
      Joint analysis for multivariate longitudinal and event time data with a change point anchored at interval-censored event time
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Yue Zhan, Cheng Zheng, Ying Zhang</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Huntington&#x27;s disease (HD) is an autosomal dominant neurodegenerative disorder characterized by motor dysfunction, psychiatric disturbances, and cognitive decline. The onset of HD is marked by severe motor impairment, which may be predicted by prior cognitive decline and, in turn, exacerbate cognitive deficits. Clinical data, however, are often collected at discrete time points, so the timing of disease onset is subject to interval censoring. To address the challenges posed by such data, we develop a joint model for multivariate longitudinal biomarkers with a change point anchored at an interval-censored event time. The model simultaneously assesses the effects of longitudinal biomarkers on the event time and the changes in biomarker trajectories following the event. We conduct a comprehensive simulation study to demonstrate the finite-sample performance of the proposed method for causal inference. Finally, we apply the method to PREDICT-HD, a multisite observational cohort study of prodromal HD individuals, to ascertain how cognitive impairment and motor dysfunction interact during disease progression.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14991v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14981v1" target="_blank" rel="noopener noreferrer">
      Block Empirical Likelihood Inference for Longitudinal Generalized Partially Linear Single-Index Models
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Tianni Zhang, Yuyao Wang, Yu Lu, and Mengfei Ran</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Generalized partially linear single-index models (GPLSIMs) provide a flexible and interpretable semiparametric framework for longitudinal outcomes by combining a low-dimensional parametric component with a nonparametric index component. For repeated measurements, valid inference is challenging because within-subject correlation induces nuisance parameters and variance estimation can be unstable in semiparametric settings. We propose a profile estimating-equation approach based on spline approximation of the unknown link function and construct a subject-level block empirical likelihood (BEL) for joint inference on the parametric coefficients and the single-index direction. The resulting BEL ratio statistic enjoys a Wilks-type chi-square limit, yielding likelihood-free confidence regions without explicit sandwich variance estimation. We also discuss practical implementation, including constrained optimization for the index parameter, working-correlation choices, and bootstrap-based confidence bands for the nonparametric component. Simulation studies and an application to the epilepsy longitudinal study illustrate the finite-sample performance.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14981v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14972v1" target="_blank" rel="noopener noreferrer">
      Use What You Know: Causal Foundation Models with Partial Graphs
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Arik Reuter, Anish Dhir, Cristiana Diaconu, Jake Robertson, Ole Ossen, Frank Hutter, Adrian Weller, Mark van der Wilk, Bernhard Schölkopf</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discovery and inference in a single step. However, in their current state, they do not allow for the incorporation of any domain knowledge, which can lead to suboptimal predictions. We bridge this gap by introducing methods to condition CFMs on causal information, such as the causal graph or more readily available ancestral information. When access to complete causal graph information is too strict a requirement, our approach also effectively leverages partial causal information. We systematically evaluate conditioning strategies and find that injecting learnable biases into the attention mechanism is the most effective method to utilise full and partial causal information. Our experiments show that this conditioning allows a general-purpose CFM to match the performance of specialised models trained on specific causal structures. Overall, our approach addresses a central hurdle on the path towards all-in-one causal foundation models: the capability to answer causal queries in a data-driven manner while effectively leveraging any amount of domain expertise.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14972v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14949v1" target="_blank" rel="noopener noreferrer">
      Max-Min Bilinear Completely Positive Programs: A Semidefinite Relaxation with Tightness Guarantees
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Sarah Yini Gao, Xindong Tang, Yancheng Yuan</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Max-min bilinear optimization models, where one agent maximizes and an adversary minimizes a common bilinear objective, serve as canonical saddle-point formulations in optimization theory. They capture, among others, two-player zero-sum games, robust and distributionally robust optimization, and adversarial machine learning. This study focuses on the subclass whose variables lie in the completely positive (CP) cone, capturing a broad family of mixed-binary quadratic max-min problems through the modelling power of completely positive programming. We show that such problems admit an equivalent single-stage linear reformulation over the COP-CP cone, defined as the Cartesian product of the copositive (COP) and CP cones. Because testing membership in COP cones is co-NP-complete, the resulting COP-CP program inherits NP-hardness. To address this challenge, we develop a hierarchy of semidefinite relaxations based on moment and sum-of-squares representations of the COP and CP cones, and flat truncation conditions are applied to certify the tightness. We show that the tightness of the hierarchy is guaranteed under mild conditions. The framework extends existing CP/COP approaches for distributionally robust optimization and polynomial games. We apply the framework to the cyclic Colonel Blotto game, an extension of Borel&#x27;s classic allocation contest. Across multiple instances, the semidefinite relaxation meets the flat-truncation conditions and solves the exact mixed-strategy equilibrium.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14949v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14947v1" target="_blank" rel="noopener noreferrer">
      Gradient Networks for Universal Magnetic Modeling of Synchronous Machines
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Junyi Li, Tim Foissner, Floran Martin, Antti Piippo, Marko Hinkkanen</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">This paper presents a physics-informed neural network approach for dynamic modeling of saturable synchronous machines, including cases with spatial harmonics. We introduce an architecture that incorporates gradient networks directly into the fundamental machine equations, enabling accurate modeling of the nonlinear and coupled electromagnetic constitutive relationship. By learning the gradient of the magnetic field energy, the model inherently satisfies energy balance (reciprocity conditions). The proposed architecture can universally approximate any physically feasible magnetic behavior and offers several advantages over lookup tables and standard machine learning models: it requires less training data, ensures monotonicity and reliable extrapolation, and produces smooth outputs. These properties further enable robust model inversion and optimal trajectory generation, often needed in control applications. We validate the proposed approach using measured and finite-element method (FEM) datasets from a 5.6-kW permanent-magnet (PM) synchronous reluctance machine. Results demonstrate accurate and physically consistent models, even with limited training data.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14947v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14907v1" target="_blank" rel="noopener noreferrer">
      Adjoint-based Shape Optimization, Machine Learning based Surrogate Models, Conditional Variational Autoencoder (CVAE), Voith Schneider propulsion (VSP), Self-propelled Ship, Propulsion Model, Hull Optimization
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Moloud Arian Maram, Georgios Bletsos, Thanh Tung Nguyen, Ahmed Hassan, Michael Palm, Thomas Rung</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Adjoint-based shape optimization of ship hulls is a powerful tool for addressing high-dimensional design problems in naval architecture, particularly in minimizing the ship resistance. However, its application to vessels that employ complex propulsion systems introduces significant challenges. They arise from the need for transient simulations extending over long periods of time with small time steps and from the reverse temporal propagation of the primal and adjoint solutions. These challenges place considerable demands on the required storage and computing power, which significantly hamper the use of adjoint methods in the industry. To address this issue, we propose a machine learning-assisted optimization framework that employs a Conditional Variational Autoencoder-based surrogate model of the propulsion system. The surrogate model replicates the time-averaged flow field induced by a Voith Schneider Propeller and replaces the geometrically and time-resolved propeller with a data-driven approximation. Primal flow verification examples demonstrate that the surrogate model achieves significant computational savings while maintaining the necessary accuracy of the resolved propeller. Optimization studies show that ignoring the propulsion system can yield designs that perform worse than the initial shape. In contrast, the proposed method produces shapes that achieve more than an 8\% reduction in resistance.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14907v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14898v1" target="_blank" rel="noopener noreferrer">
      Tarnished by Tools: Cost of Systematics in Golden Dark Siren Cosmology
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Giovanni Benetti, Koustav Chandra, Bangalore S. Sathyaprakash</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Golden dark sirens - exceptionally well-localized gravitational-wave (GW) sources without electromagnetic counterparts - offer a powerful route to precision measurements of the Hubble constant, $H_0$, with next-generation (XG) detectors. The statistical promise of this method, however, places stringent demands on waveform accuracy and detector calibration, as even small systematic errors can dominate over statistical uncertainties at high signal-to-noise ratios. We investigate the impact of waveform-modeling systematics on golden dark siren cosmology using a synthetic population of binary black holes consistent with current GW observations and analyzed in the XG-detector era. By comparing state-of-the-art waveform models against numerical-relativity-based reference signals, we quantify modeling inaccuracies from both modeling and data-analysis perspectives and assess how they propagate into biases in luminosity distance, host-galaxy association, and single-event $H_0$ inference. We find that while current waveform models often allow recovery of statistically consistent $H_0$ posteriors, small waveform-induced biases can significantly affect three-dimensional localization and host galaxy ranking, occasionally leading to incorrect redshift assignments. We further derive order-of-magnitude requirements on detector calibration accuracy needed to ensure that calibration systematics remain subdominant for golden dark sirens observed with XG networks. To realize sub-percent $H_0$ measurements with golden dark sirens will require waveform and calibration accuracies that scale as $\mathcal{O}(ρ^{-2})$ with signal-to-noise ratio, motivating sustained advances in waveform modeling, numerical relativity, and detector calibration for the XG era.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14898v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14885v1" target="_blank" rel="noopener noreferrer">
      Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Ramón Nartallo-Kaluarachchi, Renaud Lambiotte, Alain Goriely</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield&#x27;s model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14885v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14873v1" target="_blank" rel="noopener noreferrer">
      Reduction of bar fraction in paired galaxies in the SDSS
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Linlin Li, Shuai Feng, Shiyin Shen, Qi&#x27;an Deng, Ying Zu, Wenyuan Cui</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">We investigate the bar fraction in galaxy pairs from the SDSS to assess how galaxy interactions affect bar structures. Compared to isolated galaxies, close pairs exhibit a significantly reduced bar fraction at projected separations within 25 kpc. This reduction is driven almost entirely by systems showing clear merger or disturbance signatures, indicating that tidal interactions suppress bars. The decline is dominated by a decrease in weak bars, while the fraction of strong bars remains largely unchanged. Bar suppression is primarily associated with major mergers and is strongest in massive host galaxies. A weaker but statistically significant suppression is detected in minor mergers only for massive galaxies with small bulges. In contrast, no significant dependence of bar suppression on the relative orientation between pair members is found. These findings provide observational evidence that tidal perturbations in major mergers play a key role in regulating bar evolution.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14873v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14867v1" target="_blank" rel="noopener noreferrer">
      Fast and accurate quasi-atom method for simultaneous atomistic and continuum simulation of solids
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Artem Chuprov, Egor E. Nuzhin, Alexey A. Tsukanov, Nikolay V. Brilliantov</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">We report a novel hybrid method of simultaneous atomistic simulation of solids in critical regions (contacts surfaces, cracks areas, etc.), along with continuum modeling of other parts. The continuum is treated in terms of quasi-atoms of different size, comprising composite medium. The parameters of interaction potential between the quasi-atoms are optimized to match elastic properties of the composite medium to those of the atomic one. The optimization method coincides conceptually with the online Machine Learning (ML) methods, making it computationally very efficient. Such an approach allows a straightforward application of standard software packages for molecular dynamics (MD), supplemented by the ML-based optimizer. The new method is applied to model systems with a simple, pairwise Lennard-Jones potential, as well with multi-body Tersoff potential, describing covalent bonds. Using LAMMPS software we simulate collision of particles of different size. Comparing simulation results, obtained by the novel method, with full-atomic simulations, we demonstrate its accuracy, validity and overwhelming superiority in computational speed. Furthermore, we compare our method with other hybrid methods, specifically, with the closest one -- AtC (Atomic to Continuum) method. We demonstrate a significant superiority of our approach in computational speed and implementation convenience. Finally, we discuss a possible extension of the method for modeling other phenomena.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14867v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14861v1" target="_blank" rel="noopener noreferrer">
      Bias analysis of a linear order-statistic inequality index estimator: Unbiasedness under gamma populations
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Roberto Vila, Helton Saulo</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">This paper studies a class of rank-based inequality measures built from linear combinations of expected order statistics. The proposed framework unifies several well-known indices, including the classical Gini coefficient, the $m$th Gini index, extended $m$th Gini index and $S$-Gini index, and also connects to spectral inequality measures through an integral representation. We investigate the finite-sample behavior of a natural U-statistic-type estimator that averages weighted order-statistic contrasts over all subsamples of fixed size and normalizes by the sample mean. A general bias decomposition is derived in terms of components that isolate the effect of random normalization on each rank level, yielding analytical expressions that can be evaluated under broad non-negative distributions via Laplace-transform methods. Under mild moment conditions, the estimator is shown to be asymptotically unbiased. Moreover, we prove exact unbiasedness under gamma populations for any sample size, extending earlier unbiasedness results for Gini-type estimators. A Monte Carlo study is performed to numerically check that the theoretical unbiasednes under gamma populations.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14861v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14858v1" target="_blank" rel="noopener noreferrer">
      Thermal Min-Max Games: Unifying Bounded Rationality and Typical-Case Equilibrium
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Yuma Ichikawa</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Strategic-form min-max game theory examines the existence, multiplicity, selection of equilibria, and the worst-case computational complexity under perfect rationality. However, in many applications, games are drawn from an ensemble, and players exhibit bounded rationality. We introduce thermal min-max games, a thermodynamic relaxation that unifies bounded and perfect rationality by assigning each player a temperature to regulate their rationality level. To analyze typical behavior in the large-strategy limit, we develop a nested replica framework for this relaxation. This theory provides tractable predictions for typical equilibrium values and mixed-strategy statistics as functions of rationality strength, strategy-count aspect ratio, and payoff randomness. Numerical experiments demonstrate that these asymptotic predictions accurately align with the equilibrium of finite games of moderate size.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14858v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14853v1" target="_blank" rel="noopener noreferrer">
      BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Jonathan Gorard, Ammar Hakim, James Juno</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers&#x27; equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14853v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14846v1" target="_blank" rel="noopener noreferrer">
      Multi-dimensional Persistent Sheaf Laplacians for Image Analysis
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Xiang Xiang Wang, Guo-Wei Wei</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">We propose a multi-dimensional persistent sheaf Laplacian (MPSL) framework on simplicial complexes for image analysis. The proposed method is motivated by the strong sensitivity of commonly used dimensionality reduction techniques, such as principal component analysis (PCA), to the choice of reduced dimension. Rather than selecting a single reduced dimension or averaging results across dimensions, we exploit complementary advantages of multiple reduced dimensions. At a given dimension, image samples are regarded as simplicial complexes, and persistent sheaf Laplacians are utilized to extract a multiscale localized topological spectral representation for individual image samples. Statistical summaries of the resulting spectra are then aggregated across scales and dimensions to form multiscale multi-dimensional image representations. We evaluate the proposed framework on the COIL20 and ETH80 image datasets using standard classification protocols. Experimental results show that the proposed method provides more stable performance across a wide range of reduced dimensions and achieves consistent improvements to PCA-based baselines in moderate dimensional regimes.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14846v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14840v1" target="_blank" rel="noopener noreferrer">
      Statistical Validation and Vetting of Exoplanet Candidate TOI 7475.01
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Biel Escolà-Rodrigo</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">We present a comprehensive validation analysis of the exoplanet candidate TOI 7475.01 (TIC 376866659), detected by the TESS mission. Using a custom pipeline combining natural flux preservation with robust BLS detection, we identified a transit signal with a period of $3.2538$ days and a depth of $\sim 4600$ ppm. To rule out false positives, we performed centroid analysis, spatial contamination checks using Gaia DR3, and a statistical validation using triceratops. Our results show a Signal-to-Noise Ratio (SNR) of 294.13 and a False Positive Probability (FPP) of $\approx 0$. Based on the clean spatial environment, stable centroids, and high statistical probability, we validate TOI 7475.01 as a planetary companion.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14840v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14835v1" target="_blank" rel="noopener noreferrer">
      The Global Representativeness Index: A Total Variation Distance Framework for Measuring Demographic Fidelity in Survey Research
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Evan Hadfield</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Global survey research increasingly informs high-stakes decisions in AI governance and cross-cultural policy, yet no standardized metric quantifies how well a sample&#x27;s demographic composition matches its target population. Response rates and demographic quotas -- the prevailing proxies for sample quality -- measure effort and coverage but not distributional fidelity. This paper introduces the Global Representativeness Index (GRI), a framework grounded in Total Variation Distance that scores any survey sample against population benchmarks across multiple demographic dimensions on a [0, 1] scale. Validation on seven waves of the Global Dialogues survey (N = 7,500 across 60+ countries) finds fine-grained demographic GRI scores of only 0.33--0.36 -- roughly 43% of the theoretical maximum at that sample size. Cross-validation on the World Values Survey (seven waves, N = 403,000), Afrobarometer Round 9 (N = 53,000), and Latinobarometro (N = 19,000) reveals that even large probability surveys score below 0.22 on fine-grained global demographics when country coverage is limited. The GRI connects to classical survey statistics through the design effect; both metrics are recommended as a minimum summary of sample quality, since GRI quantifies demographic distance symmetrically while effective N captures the asymmetric inferential cost of underrepresentation. The framework is released as an open-source Python library with UN and Pew Research Center population benchmarks, applicable to survey research, machine learning dataset auditing, and AI evaluation benchmarks.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14835v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>

<article class="paper-card">
  <h3 class="paper-title">
    <a href="https://arxiv.org/pdf/2602.14834v1" target="_blank" rel="noopener noreferrer">
      Debiasing Central Fixation Confounds Reveals a Peripheral &quot;Sweet Spot&quot; for Human-like Scanpaths in Hard-Attention Vision
    </a>
  </h3>
  <p class="paper-meta">
    <span class="paper-authors">Pengcheng Pan, Yonekura Shogo, Yasuo Kuniyosh</span>
    <span class="paper-dot">•</span>
    <span class="paper-date">2026-02-16</span>
  </p>
  <p class="paper-abstract">Human eye movements in visual recognition reflect a balance between foveal sampling and peripheral context. Task-driven hard-attention models for vision are often evaluated by how well their scanpaths match human gaze. However, common scanpath metrics can be strongly confounded by dataset-specific center bias, especially on object-centric datasets. Using Gaze-CIFAR-10, we show that a trivial center-fixation baseline achieves surprisingly strong scanpath scores, approaching many learned policies. This makes standard metrics optimistic and blurs the distinction between genuine behavioral alignment and mere central tendency. We then analyze a hard-attention classifier under constrained vision by sweeping foveal patch size and peripheral context, revealing a peripheral sweet spot: only a narrow range of sensory constraints yields scanpaths that are simultaneously (i) above the center baseline after debiasing and (ii) temporally human-like in movement statistics. To address center bias, we propose GCS (Gaze Consistency Score), a center-debiased composite metric augmented with movement similarity. GCS uncovers a robust sweet spot at medium patch size with both foveal and peripheral vision, that is not obvious from raw scanpath metrics or accuracy alone, and also highlights a &quot;shortcut regime&quot; when the field-of-view becomes too large. We discuss implications for evaluating active perception on object-centric datasets and for designing gaze benchmarks that better separate behavioral alignment from center bias.</p>
  <a class="paper-link" href="https://arxiv.org/pdf/2602.14834v1" target="_blank" rel="noopener noreferrer">
    View PDF →
  </a>
</article>
          </div>
        </div>
      </section>
    </main>

    <footer class="site-footer">
      <div class="container footer-content">
        <p>© <span id="year"></span> Tim's Coding Blog · arXiv feed</p>
      </div>
    </footer>

    <script>
      document.getElementById("year").textContent =
        new Date().getFullYear().toString();
    </script>
  </body>
  </html>

